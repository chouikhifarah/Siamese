{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae91987",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import sklearn\n",
    "import math\n",
    "import keras\n",
    "import numpy\n",
    "import pandas\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import matplotlib.image as mpimg\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot\n",
    "from keras.models import Sequential,Model\n",
    "from keras.losses import mse,sparse_categorical_crossentropy\n",
    "from keras.layers import Dense, Conv2D, Conv1D, Conv3D, Flatten,Activation,MaxPool1D,MaxPooling1D,Dropout,LSTM,ConvLSTM2D,MaxPool2D,MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4164e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size1 = 4\n",
    "img_size2 = 1\n",
    "num_channels = 1\n",
    "latent_space_dim =24\n",
    "num_category=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdd9e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 4, 32)             4352      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 2, 64)             24832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "feature_extraction (Dense)   (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 96,867\n",
      "Trainable params: 96,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(LSTM(units=32, input_shape=(img_size1, img_size2), return_sequences=True))\n",
    "model_rnn.add(MaxPooling1D(2))\n",
    "model_rnn.add(LSTM(units=64, return_sequences=True))\n",
    "model_rnn.add(MaxPooling1D(2))\n",
    "model_rnn.add(LSTM(units=64, return_sequences=True))\n",
    "model_rnn.add(MaxPooling1D(1))\n",
    "model_rnn.add(LSTM(units=64))\n",
    "model_rnn.add(Dense(latent_space_dim, name='feature_extraction'))\n",
    "model_rnn.add(Dense(num_category, activation='softmax'))\n",
    "model_rnn.compile(loss='categorical_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c2b7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520873, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################   préparation des données #######################################\n",
    "datasetf2001 = pd.read_csv('D:/etm data/GoogleEarthEngine/Landsat_07/dataset_2001_2004/insitu_MH_2001.csv')\n",
    "data2001=np.array(datasetf2001.iloc[:, 2:6])\n",
    "datay=np.array(datasetf2001.iloc[:, 6:7])\n",
    "x_train2001, x_test2001 = train_test_split(data2001, test_size = 0.3, random_state = 0)\n",
    "y_train, y_test = train_test_split(datay, test_size = 0.3, random_state = 0)\n",
    "x_train2001 = numpy.reshape(x_train2001, newshape=( x_train2001.shape[0], x_train2001.shape[1],1))\n",
    "x_test2001 = numpy.reshape(x_test2001, newshape=( x_test2001.shape[0], x_test2001.shape[1],1))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)\n",
    "data2001.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b355c2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520873, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################   préparation des données #######################################\n",
    "datasetf2004 = pd.read_csv('D:/etm data/GoogleEarthEngine/Landsat_07/dataset_2001_2004/insitu_MH_2004.csv')\n",
    "data2004=np.array(datasetf2004.iloc[:, 2:6])\n",
    "x_train2004, x_test2004 = train_test_split(data2004, test_size = 0.3, random_state = 0)\n",
    "x_train2004 = numpy.reshape(x_train2004, newshape=(x_train2004.shape[0], x_train2004.shape[1],1))\n",
    "x_test2004 = numpy.reshape(x_test2004, newshape=( x_test2004.shape[0], x_test2004.shape[1],1))\n",
    "data2004.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e0cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1425/1425 [==============================] - 29s 12ms/step - loss: 0.9152 - accuracy: 0.5322\n",
      "Epoch 2/1000\n",
      "1161/1425 [=======================>......] - ETA: 3s - loss: 0.3718 - accuracy: 0.8333"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=5)\n",
    "hist=model_rnn.fit(x_train2001, y_train, epochs=1000, batch_size=256,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = Model(inputs=model_rnn.input,outputs=model_rnn.get_layer('feature_extraction').output)\n",
    "weights = feature_extraction.get_weights()\n",
    "for l in feature_extraction.layers:\n",
    "    l.trainable = False\n",
    "    print(l.name, l.trainable)\n",
    "# re-compile the model\n",
    "feature_extraction.compile(loss='categorical_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289860b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_in_1 = tensorflow.keras.layers.Input(shape=(img_size1, img_size2), name=\"s_input1\")\n",
    "rnn_in_2 = tensorflow.keras.layers.Input(shape=(img_size1, img_size2), name=\"s_input2\")\n",
    "concatted = tf.keras.layers.Concatenate()([feature_extraction(rnn_in_1), feature_extraction(rnn_in_2)])\n",
    "prediction = Dense(num_category, activation='softmax', name=\"classifier\")(concatted)\n",
    "Siamese_rnn=Model(inputs=[rnn_in_1,rnn_in_2],outputs=prediction)\n",
    "Siamese_rnn.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "Siamese_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5db6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################   Siamese RNN Training #######################################\n",
    "import time\n",
    "start_time = time.time()\n",
    "ces = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=10)\n",
    "history=Siamese_rnn.fit([x_train2001,x_train2004],y_train,batch_size=256,epochs=1000,callbacks=[ces]) \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fabb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2001 = numpy.reshape(data2001, newshape=(data2001.shape[0], data2001.shape[1],1,1))\n",
    "data2004 = numpy.reshape(data2004, newshape=(data2004.shape[0], data2004.shape[1],1,1))\n",
    "Y_pred=Siamese_rnn.predict([data2001,data2004])\n",
    "datasetvae2001_class = pd.DataFrame(datasetf2001['x'])\n",
    "datasetvae2004_class = pd.DataFrame(datasetf2001['x'])\n",
    "datasetvae2001_class['y'] = pd.DataFrame(datasetf2001['y'],columns=['y'])\n",
    "datasetvae2004_class['y'] = pd.DataFrame(datasetf2001['y'],columns=['y'])\n",
    "datasetvae2001_class['f1'] = pd.DataFrame(datasetf2001['f1'])\n",
    "datasetvae2001_class['f2'] = pd.DataFrame(datasetf2001['f2'])\n",
    "datasetvae2001_class['f3'] = pd.DataFrame(datasetf2001['f3'])\n",
    "datasetvae2001_class['f4'] = pd.DataFrame(datasetf2001['f4'])\n",
    "datasetvae2004_class['f1'] = pd.DataFrame(datasetf2004['f1'])\n",
    "datasetvae2004_class['f2'] = pd.DataFrame(datasetf2004['f2'])\n",
    "datasetvae2004_class['f3'] = pd.DataFrame(datasetf2004['f3'])\n",
    "datasetvae2004_class['f4'] = pd.DataFrame(datasetf2004['f4'])\n",
    "datasetvae2001_class['class'] = datay\n",
    "datasetvae2001_class['pred'] = np.argmax(Y_pred, axis=1)\n",
    "datasetvae2001_class.to_csv(r'D:/etm data/GoogleEarthEngine/Landsat_07/dataset_2001_2004/y_pred_insitu_MH_2001_rnn.csv')\n",
    "datasetvae2004_class['class'] = datay\n",
    "datasetvae2004_class['pred'] = np.argmax(Y_pred, axis=1)\n",
    "datasetvae2004_class.to_csv(r'D:/etm data/GoogleEarthEngine/Landsat_07/dataset_2001_2004/y_pred_insitu_MH_2004_rnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(datay, np.argmax(Y_pred, axis=1))\n",
    "rmse = math.sqrt(mse)\n",
    "r2=sklearn.metrics.r2_score(datay, np.argmax(Y_pred, axis=1))\n",
    "precision_sc=sklearn.metrics.precision_score(datay, np.argmax(Y_pred, axis=1), average='macro')\n",
    "f1_sc=sklearn.metrics.f1_score(datay, np.argmax(Y_pred, axis=1), average='macro')\n",
    "confusion_mat=sklearn.metrics.confusion_matrix(datay, np.argmax(Y_pred, axis=1))\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(datay, np.argmax(Y_pred, axis=1), pos_label=2)\n",
    "auc=sklearn.metrics.auc(fpr, tpr)\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score=recall_score(datay, np.argmax(Y_pred, axis=1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aab357",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4346c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23bd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e03643",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb87f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=sklearn.metrics.accuracy_score(datay, np.argmax(Y_pred, axis=1))\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feff238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(confusion_mat, index = [\"0.low\",\"1.high\",\"2.very high\"],columns = [\"0.low\",\"1.high\",\"2.very high\"])\n",
    "plt.figure(figsize = (5,5))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\",cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4e4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
